# In-Transit ğŸ¬âœ¨

An AI-powered video processing pipeline that transforms long-form content into engaging, condensed videos with seamless AI transitions. Built for the Google Nano Banana Hackathon in San Francisco (September 6-7, 2025).

## ğŸ† Hackathon Achievement

This project was developed during the 48-hour Google Nano Banana Hackathon hosted by Google DeepMind and Cerebral Valley in San Francisco. The hackathon featured Gemini 2.5 Flash Image Preview (Nano Banana) and had a prize pool exceeding $400,000 with partnerships from Fal AI and ElevenLabs.

## ğŸš€ How It Works

In-Transit transforms lengthy videos into concise, engaging content through an intelligent 3-stage pipeline:

```mermaid
graph TD
    A[ğŸ“¹ Input Video] --> B[ğŸ™ï¸ Transcription Service<br/>ElevenLabs API]
    B --> C[ğŸ“ Original Transcript<br/>.srt file]
    C --> D[ğŸ¤– AI Text Processing<br/>Gemini AI]
    D --> E[ğŸ“‹ Condensed Transcript<br/>25% most important content]
    E --> F[ğŸ¬ Video Processing<br/>Nano Banana + Fal AI]
    F --> G[âœ¨ Final Seamless Video<br/>with AI transitions]
    
    F --> H[ğŸ–¼ï¸ Frame Extraction<br/>Key transition points]
    H --> I[ğŸŒ Nano Banana<br/>Intermediate frame generation]
    I --> J[ğŸ”„ Fal AI AMT<br/>Frame interpolation]
    J --> K[ğŸ­ Seamless Transitions<br/>Between segments]
    K --> G
    
    style A fill:#e1f5fe
    style G fill:#c8e6c9
    style I fill:#fff3e0
    style D fill:#f3e5f5
```

## ğŸ¯ Features

### ğŸ”¥ **Seamless Mode** (Default)
- **AI-Powered Transitions**: Uses Google's Nano Banana model for intelligent intermediate frame generation
- **Frame Interpolation**: Fal AI's AMT technology creates smooth transitions between video segments
- **Content Intelligence**: Gemini AI identifies and preserves the most important 25% of content

### âš¡ **Jump-Cut Mode**
- **Rapid Processing**: Fast-paced video creation with direct segment stitching
- **No Transitions**: Perfect for quick content summaries

### âœ‚ï¸ **Manual Cut Mode**
- **Precise Control**: Manual video cutting based on `xxx` timestamps
- **Frame Extraction**: Saves transition frames for manual editing

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/in-transit.git
cd in-transit

# Install dependencies
pip install moviepy fal-client google-generativeai opencv-python pillow numpy requests python-dotenv

# Set up your API keys
cp .env.example .env
# Edit .env with your API keys
```

## ğŸ”‘ API Keys Setup

Create a `.env` file in the root directory:

```env
ELEVENLABS_API_KEY="your_elevenlabs_api_key"
GEMINI_API_KEY="your_google_gemini_api_key"
FAL_KEY="your_fal_api_key"
```

### Where to get API keys:
- **ElevenLabs**: [https://elevenlabs.io/](https://elevenlabs.io/)
- **Google Gemini**: [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)
- **Fal AI**: [https://fal.ai/](https://fal.ai/)

## ğŸ® Usage

### One-Command Pipeline

The simplest way to use In-Transit - run the complete pipeline with a single command:

```bash
cd scripts
python transcription_service.py --video your_video.mp4
```

This will automatically:
1. ğŸ™ï¸ Transcribe your video using ElevenLabs
2. ğŸ¤– Process and condense the transcript with Gemini AI  
3. ğŸ¬ Generate the final seamless video with AI transitions

### Advanced Usage

For more control over the process:

```bash
# Seamless mode with custom settings
python scripts/video_cutter2.py --mode seamless --video video.mp4 --transcript transcript.srt --amt-fps 12 --amt-passes 2

# Jump-cut mode (faster processing)
python scripts/video_cutter2.py --mode jumpcut --video video.mp4 --transcript transcript.srt

# Manual cutting mode
python scripts/video_cutter2.py --mode manualcut --video video.mp4 --transcript transcript.srt
```

## ğŸ“ Project Structure

```
in-transit/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ transcription_service.py    # ğŸ™ï¸ Main pipeline entry point
â”‚   â”œâ”€â”€ text_process.py            # ğŸ¤– AI text processing
â”‚   â””â”€â”€ video_cutter2.py           # ğŸ¬ Video processing with AI transitions
â”œâ”€â”€ media/                         # ğŸ“¹ Input videos
â”œâ”€â”€ output/                        # ğŸ“¤ Generated transcripts and videos
â”œâ”€â”€ docs/                          # ğŸ“š Documentation
â””â”€â”€ .env                          # ğŸ”‘ API keys (create this)
```

## ğŸ¬ Example Output

**ğŸ”¥ [Download the example video: `media/condensed_GreekFinCrisis_seamless.mp4`](./media/condensed_GreekFinCrisis_seamless.mp4)**

This demonstrates our complete pipeline processing a Greek Financial Crisis educational video:

- **ğŸ“¹ Original**: 8-minute educational video about the Greek Financial Crisis
- **âœ¨ Processed**: **2-minute condensed version** with seamless AI transitions
- **ğŸ“Š Compression**: **75% reduction** in length while preserving key information
- **ğŸ”„ AI Magic**: 12 seamless transitions generated using:
  - ğŸŒ **Nano Banana**: Intelligent intermediate frame generation
  - ğŸ”„ **Fal AI AMT**: Advanced frame interpolation
  - ğŸ¤– **Gemini AI**: Content analysis for optimal segment selection

**Try it yourself:**
```bash
cd scripts
python transcription_service.py --video GreekFinCrisis.mp4
```

The processed video demonstrates how In-Transit intelligently identifies the most important segments of educational content and creates smooth transitions that maintain narrative flow.

## ğŸ§ª Technologies Used

- **ğŸŒ Google Nano Banana (Gemini 2.5 Flash)**: Intelligent intermediate frame generation
- **ğŸ™ï¸ ElevenLabs**: High-quality speech-to-text transcription
- **ğŸ”„ Fal AI AMT**: Advanced frame interpolation for seamless transitions
- **ğŸ¬ MoviePy**: Video processing and manipulation
- **ğŸ–¼ï¸ OpenCV**: Computer vision and frame alignment
- **ğŸ“ Gemini AI**: Content analysis and transcript processing

## ğŸ—ï¸ Architecture

In-Transit uses a modular architecture with three main components:

1. **Transcription Layer**: Converts audio to timestamped text
2. **Intelligence Layer**: AI-powered content analysis and condensation  
3. **Synthesis Layer**: Video reconstruction with AI-generated transitions

Each layer is optimized for quality and performance, with graceful fallbacks and error handling.

## ğŸ¯ Hackathon Judging Criteria Achievement

- **âœ¨ Innovation & Wow Factor (40%)**: Novel use of Nano Banana for video transition generation
- **âš™ï¸ Technical Execution (30%)**: Robust pipeline with multiple AI services integration
- **ğŸŒ Impact & Utility (20%)**: Solves real content creation challenges for educators and creators
- **ğŸ¤ Presentation Quality (10%)**: Clear documentation and example demonstrations

## ğŸš§ Future Enhancements

- ğŸŒ Web interface for easier video processing
- ğŸ¨ Custom transition styles and effects
- ğŸ“Š Analytics dashboard for content optimization
- ğŸ”€ Batch processing for multiple videos
- ğŸ¯ Industry-specific content templates

## ğŸ¤ Contributing

Built during the Nano Banana Hackathon! Contributions welcome for post-hackathon improvements.

## ğŸ“„ License

MIT License - Feel free to use and modify for your projects!

---

*Created with â¤ï¸ during the Google Nano Banana Hackathon 2025 in San Francisco*